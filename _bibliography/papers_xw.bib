@inproceedings{ASSETS2025Wang,
abbr={ASSETS},
author = {Wang, Xiyue and Kayukawa, Seita and Takagi, Hironobu and Masoero, Giorgia and Asakawa, Chieko},
title = {Engaging Visually Impaired People in Science Museums Through an ImmersiveWorkshop: Practices, Challenges, and Opportunities},
year = {2025},
isbn = {9798400706769},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663547.3746348},
doi = {10.1145/3663547.3746348},
abstract = {
As a crucial place for informal learning, science museums feature multimedia exhibitions and themed workshops. However, their accessibility for visually impaired visitors remains underexplored. This study leverages workshops in science museums as a platform to enhance accessibility. We iteratively designed an accessible workshop titled \emph{\quot{Learning by Touch--Life in Space}} in collaboration with diverse stakeholders. Once launched as a recurring museum program, 28 visually impaired participants attended over the course of a year and provided feedback on its accessibility.
Additional insights were gathered through focus group interviews with six workshop staff and seven participants, focusing on current practices, accessibility challenges, and technological possibilities for workshops and exhibitions.
Our findings contribute: (1) a participatory and adaptive framework for accessible science workshop design; (2) practical accessibility guidelines for museum staff on training, co-development, and content planning; and (3) actions for applying emerging technologies to support flexible, social, and enjoyable science experiences for visually impaired visitors.
},
series = {ASSETS '25},
html = {https://doi.org/10.1145/3663547.3746348},
pdf={XWang_ASSETS25_EngageWorkshop.pdf},
selected={true}
}

@inproceedings{ASSETS2025Tsutsui,
abbr={ASSETS},
author = {Tsutsui, Ayaka and Wang, Xiyue and Takagi, Hironobu and Asakawa, Chieko},
title = {Investigating “Touch and Talk” for Blind and Low Vision People: Science Communication Assistance Through Exploring Multiple Tactile Objects},
year = {2025},
isbn = {9798400706769},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663547.3746373},
doi = {10.1145/3663547.3746373},
abstract = {
Tactile exploration is extremely important for blind and low vision
(BLV) users to understand concepts. Although Interactive 3D
Models that integrate modalities such as audio and vibration have
been developed to create self-directed tactile exploration experiences,
they depend on pre-defined commands and fixed interaction
flows, which limit opportunities for adaptive guidance. In this study,
we examine how interactive dialogue and temporal dynamics can
enhance tactile learning experiences, particularly in the context
of science communication where BLV users frequently encounter
abstract and spatially complex topics. We conducted interviews
with 22 tactile guidance experts to identify effective explanation
techniques and communication strategies. We then employed a
technology probe that combines multiple tactile models with a
voice-based “Touch and Talk” system, using a Wizard-of-Oz approach
with 10 BLV participants. The experiment revealed strategies
that support understanding and foster curiosity. Based on findings,
we propose a set of design implications aimed at supporting BLV
users in autonomously exploring complex scientific content.
},
series = {ASSETS '25},
html = {https://doi.org/10.1145/3663547.3746373},
pdf={ATsutsui_ASSETS25_InvestigatingTouchAndTalk.pdf},
selected={true}
}

@inproceedings{W4A2024,
abbr={W4A},
author = {Wang, Xiyue and Kayukawa, Seita and Takagi, Hironobu and Masoero, Giorgia and Asakawa, Chieko},
title = {Direct or Immersive? Comparing Smartphone-based Museum Guide Systems for Blind Visitors},
year = {2024},
isbn = {9798400710308},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677846.3677856},
doi = {10.1145/3677846.3677856},
abstract = {Guiding blind visitors to navigate and comprehend exhibits is crucial in museums. Two paradigms of smartphone-based guide systems have emerged: one provides direct interaction with turn-by-turn navigation and screen reader-controlled audio description, while the other offers immersive experiences with spatialized sound navigation and automatically playing audio content. However, it remains unclear which system better supports museum experiences. In a comparative study at a science museum with seven blind participants experiencing both systems, we found that immersive spatialized sound was more effective and preferred for navigation. For information provision, participants valued audio autoplay’s minimal operation but expressed a need for on-demand direct control. The touch instructions provided by both systems were found inadequate for aiding interactions with tactile exhibits. Our findings suggest that a hybrid system, which adds direct interaction to the immersive experience and is adaptable to both environment and user requirements, could enhance the museum experience for blind visitors.},
booktitle = {Proceedings of the 21st International Web for All Conference},
pages = {10–22},
numpages = {13},
keywords = {Visual impairment, Museum accessibility, Navigation, Information provision, Tactile exhibits},
location = {Singapore, Singapore},
series = {W4A '24},
html = {https://doi.org/10.1145/3677846.3677856},
pdf={XWang_W4A2024_DirectOrImmersive_AuthorVersion.pdf},
video={https://youtu.be/jpBv6nY3N6Q},
selected={true}
}

@article{CACM2024,
abbr={CACM},
author = {Wang, Xiyue and Kayukawa, Seita and Takagi, Hironobu and Asakawa, Chieko},
title = {BentoMuseum: 3D and Layered Interactive Museum Map for Blind Visitors},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/3617678},
doi = {10.1145/3617678},
abstract = {Obtaining information before a visit is one of the priority needs and challenges for blind museum visitors. We propose BentoMuseum, a layered, stackable, and three-dimensional museum map that makes complex structural information accessible by allowing explorations on a floor and between floors. Touchpoints are embedded to provide audio-tactile interactions that allow a user to learn the museum’s exhibits and navigation when one floor is placed on a touch screen. Using a tour design task, we invited 12 first-time blind visitors to explore the museum building, choose exhibits that attracted them, and build a mental map with exhibit names and directions. The results show that the system is useful in obtaining information that links geometric shapes, contents, and locations to then build a rough mental map. The connected floors and spatial structures motivated users to explore. Moreover, having a rough mental map enhanced orientation and confidence while traveling in the museum.},
journal = {Commun. ACM},
month = oct,
pages = {93–102},
numpages = {10},
html = {https://doi.org/10.1145/3617678},
pdf={XWang_CACM24_BentoMuseum.pdf},
video={https://youtu.be/q9J1hoB4jh8},
selected={true}
}

@inproceedings{ASSETS2023,
abbr={ASSETS},
author = {Wang, Xiyue and Kayukawa, Seita and Takagi, Hironobu and Asakawa, Chieko},
title = {TouchPilot: Designing a Guidance System That Assists Blind People in Learning Complex 3D Structures},
year = {2023},
isbn = {9798400702204},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597638.3608426},
doi = {10.1145/3597638.3608426},
abstract = {Making complex structures accessible to blind people is challenging due to the need for skilled explainers. Interactive 3D printed models (I3Ms) have been developed to enable independent learning of 3D models through activating audio labels. However, they present single-layered information and require users to identify interactive elements through a pinpointing action, which might be insufficient for learning complex and unfamiliar subjects. In this paper, we investigate I3Ms for complex structures. We propose TouchPilot, a guidance system designed based on a study that observed learner-explainer interaction styles. TouchPilot guides users step by step through navigation, exploration of hierarchical elements, and confirmation of their entire areas. A follow-up study found that the guidance system led to better learning outcomes and higher independence compared to a pinpointing system. Feedback suggests that being primed by the guidance system systematically, followed by pinpointing freely for review, is preferred for learning complex structures.},
booktitle = {Proceedings of the 25th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {5},
numpages = {18},
keywords = {visual impairments, guidance, interactive 3D printed models, computer vision},
location = {New York, NY, USA},
series = {ASSETS '23},
html = {https://doi.org/10.1145/3597638.3608426},
project = {https://xiyue-w.github.io/projects/TouchPilot/},
selected={true}
}

@inproceedings{ASSETS2022,
abbr={ASSETS},
author = {Wang, Xiyue and Kayukawa, Seita and Takagi, Hironobu and Asakawa, Chieko},
title = {BentoMuseum: 3D and Layered Interactive Museum Map for Blind Visitors},
year = {2022},
isbn = {9781450392587},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3517428.3544811},
doi = {10.1145/3517428.3544811},
abstract = {Obtaining information before a visit is one of the priority needs and challenges for blind museum visitors. We propose BentoMuseum, a layered, stackable, and three-dimensional museum map that makes complex structural information accessible by allowing explorations on a floor and between floors. Touchpoints are embedded to provide audio-tactile interactions that allow a user to learn the museum’s exhibits and navigation when one floor is placed on a touch screen. Using a tour design task, we invited 12 first-time blind visitors to explore the museum building, chose exhibits that attracted them, and built a mental map with exhibit names and directions. The results show that the system is useful in obtaining information that links geometric shapes, contents, and locations to then build a rough mental map. The connected floors and spatial structures motivated users to explore. Moreover, having a rough mental map enhanced orientation and confidence when traveling through the museum.},
booktitle = {Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {35},
numpages = {14},
keywords = {information access, 3D structure, touch screen, audio-tactile},
location = {Athens, Greece},
series = {ASSETS '22},
html = {https://doi.org/10.1145/3517428.3544811},
project = {https://xiyue-w.github.io/projects/BentoMuseum/},
selected={true}
}

@inproceedings{CHI2021,
abbr={CHI},
author = {Wang, Xiyue and Takashima, Kazuki and Adachi, Tomoaki and Kitamura, Yoshifumi},
title = {Can Playing with Toy Blocks Reflect Behavior Problems in Children?},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445119},
doi = {10.1145/3411764.3445119},
abstract = { Although children's behavioral and mental problems are generally diagnosed in clinical settings, the prediction and awareness of children’s mental wellness in daily settings are getting increased attention. Toy blocks are both accessible in most children’s daily lives and provide physicality as a unique non-verbal channel to express their inner world. In this paper, we propose a toy block approach for predicting a range of behavior problems in young children (4-6 years old) measured by the Child Behavior Checklist (CBCL). We defined and classified a set of quantitative play actions from IMU-embedded toy blocks. Play data collected from 78 preschoolers revealed that specific play actions and patterns indicate total problems, internalizing problems, and aggressive behavior in children. The results align with our qualitative observations, and suggest the potential of predicting the clinical behavior problems of children based on short free-play sessions with sensor-embedded toy blocks. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {540},
numpages = {14},
keywords = {Well-being, Tangibles for health, Motion data, Toy blocks, CBCL, Behavior problems, Children, Free play},
location = {Yokohama, Japan},
series = {CHI '21},
html = {https://doi.org/10.1145/3411764.3445119},
pdf={xwang_CHI_2021_CanBlocksReflectBehaviorProblems.pdf},
video={https://youtu.be/Ib3dvQK3Qb4},
selected={false}
}

@article{10.1145/3381016,
abbr={IMWUT},
author = {Wang, Xiyue and Takashima, Kazuki and Adachi, Tomoaki and Finn, Patrick and Sharlin, Ehud and Kitamura, Yoshifumi},
title = {AssessBlocks: Exploring Toy Block Play Features for Assessing Stress in Young Children after Natural Disasters},
year = {2020},
issue_date = {March 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {1},
url = {https://doi.org/10.1145/3381016},
doi = {10.1145/3381016},
abstract = {Natural disasters cause long-lasting mental health problems such as PTSD in children. Following the 2011 Earthquake and Tsunami in Japan, we witnessed a shift of toy block play behavior in young children who suffered from stress after the disaster. The behavior reflected their emotional responses to the traumatic event. In this paper, we explore the feasibility of using data captured from block-play to assess children's stress after a major natural disaster. We prototyped sets of sensor-embedded toy blocks, AssessBlocks, that automate quantitative play data acquisition. During a three-year period, the blocks were dispatched to fifty-two post-disaster children. Within a free play session, we captured block features, a child's playing behavior, and stress evaluated by several methods. The result from our analysis reveal correlations between block play features and stress measurements and show initial promise of using the effectiveness of using AssessBlocks to assess children's stress after a disaster. We provide detailed insights into the potential as well as the challenges of our approach and unique conditions. From these insights we summarize guidelines for future research in automated play assessment systems that support children's mental health.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {30},
numpages = {29},
keywords = {tangibles for health, stress assessment, toy blocks, well being, play, children, PTSD},
html={https://dl.acm.org/doi/10.1145/3381016},
pdf={xwang_IMWUT_2020_AssessBlocks.pdf},
video={https://www.youtube.com/watch?v=L0QFOrar6AI},
selected={false}
}

@inproceedings{10.1145/3384657.3384800,
abbr={AHs},
author = {Elagroudy, Passant and Wang, Xiyue and Stemasov, Evgeny and Hirzle, Teresa and Shishkovets, Svetlana and Mehrotra, Siddharth and Schmidt, Albrecht},
title = {SpotlessMind: A Design Probe for Eliciting Attitudes towards Sharing Neurofeedback},
year = {2020},
isbn = {9781450376037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384657.3384800},
doi = {10.1145/3384657.3384800},
abstract = {Mutual understanding via sharing and interpreting inner states is socially rewarding. Prior research shows that people find Brain-Computer Interfaces (BCIs) a suitable tool to implicitly communicate their cognitive states. In this paper, we conduct an online survey (N=43) to identify design parameters for systems that implicitly share cognitive states. We achieve this by designing a research probe called "SpotlessMind" to artistically share brain occupancy with another while considering the bystanders' experience to elicit user responses. Our results show that 98 percent would like to see the installation. People would use it as a gesture of openness and as a communication mediator. Abstracting visual, auditory, and somatosensory depictions is a good trade-off between understandability and users' privacy protection. Our work supports designing engaging prototypes that promote empathy, cognitive awareness and convergence between individuals.},
booktitle = {Proceedings of the Augmented Humans International Conference},
articleno = {24},
numpages = {8},
keywords = {Design Framework, Brain Occupancy, Collaborative Art, EEG, Brain-Computer Interfaces, Installation, Cognitive States},
location = {Kaiserslautern, Germany},
series = {AHs '20},
html={https://dl.acm.org/doi/10.1145/3384657.3384800},
pdf={PElagroudy_Ahs_2020SpotlessMind.pdf}
}