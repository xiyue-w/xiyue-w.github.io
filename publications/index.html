<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Xiyue  Wang | publications</title>
<meta name="description" content="Xiyue Wang's Web Page.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåï</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

  <script src="/assets/js/theme.js"></script>
  <!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Xiyue</span>   Wang
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          

          <!-- Other pages in _pages folder -->
          <!--  -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/artworks/">
                artworks
                
              </a>
          </li>
          
          
          

          <!-- CV link -->
          <!-- <li class="nav-item">
            <a class="nav-link" href="https://xiyuewang.wixsite.com/home", target="_blank">artwork</a>
          </li> -->
          <li class="nav-item">
            <a class="nav-link" href="/assets/pdf/XiyueWang_CV_20250930.pdf">CV</a>
          </li>
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="publications">
<h1>Journal / International Conference Papers (peer-reviewed)</h1>

  <h2 class="year">2025</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ASSETS</abbr>
    
  
  </div>

  <div id="ASSETS2025Wang" class="col-sm-8">
    
      <div class="title">Engaging Visually Impaired People in Science Museums Through an ImmersiveWorkshop: Practices, Challenges, and Opportunities</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Wang, Xiyue</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kayukawa, Seita,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Takagi, Hironobu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Asakawa, Chieko
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 27th International ACM SIGACCESS Conference on Computers and Accessibility</em>
      
      
        2025
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1145/3663547.3746348" class="btn btn-sm z-depth-0" role="button" target="_blank">DOI</a>
    
    
    
      
      <a href="/assets/pdf/XWang_ASSETS25_EngageWorkshop.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>
As a crucial place for informal learning, science museums feature multimedia exhibitions and themed workshops. However, their accessibility for visually impaired visitors remains underexplored. This study leverages workshops in science museums as a platform to enhance accessibility. We iteratively designed an accessible workshop titled <i>\quotLearning by Touch‚ÄìLife in Space</i> in collaboration with diverse stakeholders. Once launched as a recurring museum program, 28 visually impaired participants attended over the course of a year and provided feedback on its accessibility.
Additional insights were gathered through focus group interviews with six workshop staff and seven participants, focusing on current practices, accessibility challenges, and technological possibilities for workshops and exhibitions.
Our findings contribute: (1) a participatory and adaptive framework for accessible science workshop design; (2) practical accessibility guidelines for museum staff on training, co-development, and content planning; and (3) actions for applying emerging technologies to support flexible, social, and enjoyable science experiences for visually impaired visitors.
</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ASSETS</abbr>
    
  
  </div>

  <div id="ASSETS2025Tsutsui" class="col-sm-8">
    
      <div class="title">Investigating ‚ÄúTouch and Talk‚Äù for Blind and Low Vision People: Science Communication Assistance Through Exploring Multiple Tactile Objects</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Tsutsui, Ayaka,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Wang, Xiyue</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Takagi, Hironobu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Asakawa, Chieko
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 27th International ACM SIGACCESS Conference on Computers and Accessibility</em>
      
      
        2025
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1145/3663547.3746373" class="btn btn-sm z-depth-0" role="button" target="_blank">DOI</a>
    
    
    
      
      <a href="/assets/pdf/ATsutsui_ASSETS25_InvestigatingTouchAndTalk.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>
Tactile exploration is extremely important for blind and low vision
(BLV) users to understand concepts. Although Interactive 3D
Models that integrate modalities such as audio and vibration have
been developed to create self-directed tactile exploration experiences,
they depend on pre-defined commands and fixed interaction
flows, which limit opportunities for adaptive guidance. In this study,
we examine how interactive dialogue and temporal dynamics can
enhance tactile learning experiences, particularly in the context
of science communication where BLV users frequently encounter
abstract and spatially complex topics. We conducted interviews
with 22 tactile guidance experts to identify effective explanation
techniques and communication strategies. We then employed a
technology probe that combines multiple tactile models with a
voice-based ‚ÄúTouch and Talk‚Äù system, using a Wizard-of-Oz approach
with 10 BLV participants. The experiment revealed strategies
that support understanding and foster curiosity. Based on findings,
we propose a set of design implications aimed at supporting BLV
users in autonomously exploring complex scientific content.
</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2024</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">W4A</abbr>
    
  
  </div>

  <div id="W4A2024" class="col-sm-8">
    
      <div class="title">Direct or Immersive? Comparing Smartphone-based Museum Guide Systems for Blind Visitors</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Wang, Xiyue</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kayukawa, Seita,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Takagi, Hironobu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Masoero, Giorgia,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Asakawa, Chieko
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 21st International Web for All Conference</em>
      
      
        2024
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1145/3677846.3677856" class="btn btn-sm z-depth-0" role="button" target="_blank">DOI</a>
    
    
    
      
      <a href="/assets/pdf/XWang_W4A2024_DirectOrImmersive_AuthorVersion.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="https://youtu.be/jpBv6nY3N6Q" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Guiding blind visitors to navigate and comprehend exhibits is crucial in museums. Two paradigms of smartphone-based guide systems have emerged: one provides direct interaction with turn-by-turn navigation and screen reader-controlled audio description, while the other offers immersive experiences with spatialized sound navigation and automatically playing audio content. However, it remains unclear which system better supports museum experiences. In a comparative study at a science museum with seven blind participants experiencing both systems, we found that immersive spatialized sound was more effective and preferred for navigation. For information provision, participants valued audio autoplay‚Äôs minimal operation but expressed a need for on-demand direct control. The touch instructions provided by both systems were found inadequate for aiding interactions with tactile exhibits. Our findings suggest that a hybrid system, which adds direct interaction to the immersive experience and is adaptable to both environment and user requirements, could enhance the museum experience for blind visitors.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CACM</abbr>
    
  
  </div>

  <div id="CACM2024" class="col-sm-8">
    
      <div class="title">BentoMuseum: 3D and Layered Interactive Museum Map for Blind Visitors</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Wang, Xiyue</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kayukawa, Seita,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Takagi, Hironobu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Asakawa, Chieko
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Commun. ACM</em>
      
      
        2024
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1145/3617678" class="btn btn-sm z-depth-0" role="button" target="_blank">DOI</a>
    
    
    
      
      <a href="/assets/pdf/XWang_CACM24_BentoMuseum.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="https://youtu.be/q9J1hoB4jh8" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Obtaining information before a visit is one of the priority needs and challenges for blind museum visitors. We propose BentoMuseum, a layered, stackable, and three-dimensional museum map that makes complex structural information accessible by allowing explorations on a floor and between floors. Touchpoints are embedded to provide audio-tactile interactions that allow a user to learn the museum‚Äôs exhibits and navigation when one floor is placed on a touch screen. Using a tour design task, we invited 12 first-time blind visitors to explore the museum building, choose exhibits that attracted them, and build a mental map with exhibit names and directions. The results show that the system is useful in obtaining information that links geometric shapes, contents, and locations to then build a rough mental map. The connected floors and spatial structures motivated users to explore. Moreover, having a rough mental map enhanced orientation and confidence while traveling in the museum.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ASSETS</abbr>
    
  
  </div>

  <div id="ASSETS2023" class="col-sm-8">
    
      <div class="title">TouchPilot: Designing a Guidance System That Assists Blind People in Learning Complex 3D Structures</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Wang, Xiyue</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kayukawa, Seita,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Takagi, Hironobu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Asakawa, Chieko
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 25th International ACM SIGACCESS Conference on Computers and Accessibility</em>
      
      
        2023
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1145/3597638.3608426" class="btn btn-sm z-depth-0" role="button" target="_blank">DOI</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="https://xiyue-w.github.io/projects/TouchPilot/" class="btn btn-sm z-depth-0" role="button" target="_blank">Project Page</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Making complex structures accessible to blind people is challenging due to the need for skilled explainers. Interactive 3D printed models (I3Ms) have been developed to enable independent learning of 3D models through activating audio labels. However, they present single-layered information and require users to identify interactive elements through a pinpointing action, which might be insufficient for learning complex and unfamiliar subjects. In this paper, we investigate I3Ms for complex structures. We propose TouchPilot, a guidance system designed based on a study that observed learner-explainer interaction styles. TouchPilot guides users step by step through navigation, exploration of hierarchical elements, and confirmation of their entire areas. A follow-up study found that the guidance system led to better learning outcomes and higher independence compared to a pinpointing system. Feedback suggests that being primed by the guidance system systematically, followed by pinpointing freely for review, is preferred for learning complex structures.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ASSETS</abbr>
    
  
  </div>

  <div id="ASSETS2022" class="col-sm-8">
    
      <div class="title">BentoMuseum: 3D and Layered Interactive Museum Map for Blind Visitors</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Wang, Xiyue</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kayukawa, Seita,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Takagi, Hironobu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Asakawa, Chieko
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility</em>
      
      
        2022
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1145/3517428.3544811" class="btn btn-sm z-depth-0" role="button" target="_blank">DOI</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="https://xiyue-w.github.io/projects/BentoMuseum/" class="btn btn-sm z-depth-0" role="button" target="_blank">Project Page</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Obtaining information before a visit is one of the priority needs and challenges for blind museum visitors. We propose BentoMuseum, a layered, stackable, and three-dimensional museum map that makes complex structural information accessible by allowing explorations on a floor and between floors. Touchpoints are embedded to provide audio-tactile interactions that allow a user to learn the museum‚Äôs exhibits and navigation when one floor is placed on a touch screen. Using a tour design task, we invited 12 first-time blind visitors to explore the museum building, chose exhibits that attracted them, and built a mental map with exhibit names and directions. The results show that the system is useful in obtaining information that links geometric shapes, contents, and locations to then build a rough mental map. The connected floors and spatial structures motivated users to explore. Moreover, having a rough mental map enhanced orientation and confidence when traveling through the museum.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CHI</abbr>
    
  
  </div>

  <div id="CHI2021" class="col-sm-8">
    
      <div class="title">Can Playing with Toy Blocks Reflect Behavior Problems in Children?</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Wang, Xiyue</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Takashima, Kazuki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Adachi, Tomoaki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kitamura, Yoshifumi
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</em>
      
      
        2021
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1145/3411764.3445119" class="btn btn-sm z-depth-0" role="button" target="_blank">DOI</a>
    
    
    
      
      <a href="/assets/pdf/xwang_CHI_2021_CanBlocksReflectBehaviorProblems.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="https://youtu.be/Ib3dvQK3Qb4" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p> Although children‚Äôs behavioral and mental problems are generally diagnosed in clinical settings, the prediction and awareness of children‚Äôs mental wellness in daily settings are getting increased attention. Toy blocks are both accessible in most children‚Äôs daily lives and provide physicality as a unique non-verbal channel to express their inner world. In this paper, we propose a toy block approach for predicting a range of behavior problems in young children (4-6 years old) measured by the Child Behavior Checklist (CBCL). We defined and classified a set of quantitative play actions from IMU-embedded toy blocks. Play data collected from 78 preschoolers revealed that specific play actions and patterns indicate total problems, internalizing problems, and aggressive behavior in children. The results align with our qualitative observations, and suggest the potential of predicting the clinical behavior problems of children based on short free-play sessions with sensor-embedded toy blocks. </p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IMWUT</abbr>
    
  
  </div>

  <div id="10.1145/3381016" class="col-sm-8">
    
      <div class="title">AssessBlocks: Exploring Toy Block Play Features for Assessing Stress in Young Children after Natural Disasters</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Wang, Xiyue</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Takashima, Kazuki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Adachi, Tomoaki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Finn, Patrick,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sharlin, Ehud,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kitamura, Yoshifumi
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.</em>
      
      
        2020
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://dl.acm.org/doi/10.1145/3381016" class="btn btn-sm z-depth-0" role="button" target="_blank">DOI</a>
    
    
    
      
      <a href="/assets/pdf/xwang_IMWUT_2020_AssessBlocks.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="https://www.youtube.com/watch?v=L0QFOrar6AI" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Natural disasters cause long-lasting mental health problems such as PTSD in children. Following the 2011 Earthquake and Tsunami in Japan, we witnessed a shift of toy block play behavior in young children who suffered from stress after the disaster. The behavior reflected their emotional responses to the traumatic event. In this paper, we explore the feasibility of using data captured from block-play to assess children‚Äôs stress after a major natural disaster. We prototyped sets of sensor-embedded toy blocks, AssessBlocks, that automate quantitative play data acquisition. During a three-year period, the blocks were dispatched to fifty-two post-disaster children. Within a free play session, we captured block features, a child‚Äôs playing behavior, and stress evaluated by several methods. The result from our analysis reveal correlations between block play features and stress measurements and show initial promise of using the effectiveness of using AssessBlocks to assess children‚Äôs stress after a disaster. We provide detailed insights into the potential as well as the challenges of our approach and unique conditions. From these insights we summarize guidelines for future research in automated play assessment systems that support children‚Äôs mental health.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">AHs</abbr>
    
  
  </div>

  <div id="10.1145/3384657.3384800" class="col-sm-8">
    
      <div class="title">SpotlessMind: A Design Probe for Eliciting Attitudes towards Sharing Neurofeedback</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Elagroudy, Passant,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Wang, Xiyue</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Stemasov, Evgeny,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hirzle, Teresa,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shishkovets, Svetlana,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Mehrotra, Siddharth,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Schmidt, Albrecht
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the Augmented Humans International Conference</em>
      
      
        2020
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://dl.acm.org/doi/10.1145/3384657.3384800" class="btn btn-sm z-depth-0" role="button" target="_blank">DOI</a>
    
    
    
      
      <a href="/assets/pdf/PElagroudy_Ahs_2020SpotlessMind.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Mutual understanding via sharing and interpreting inner states is socially rewarding. Prior research shows that people find Brain-Computer Interfaces (BCIs) a suitable tool to implicitly communicate their cognitive states. In this paper, we conduct an online survey (N=43) to identify design parameters for systems that implicitly share cognitive states. We achieve this by designing a research probe called "SpotlessMind" to artistically share brain occupancy with another while considering the bystanders‚Äô experience to elicit user responses. Our results show that 98 percent would like to see the installation. People would use it as a gesture of openness and as a communication mediator. Abstracting visual, auditory, and somatosensory depictions is a good trade-off between understandability and users‚Äô privacy protection. Our work supports designing engaging prototypes that promote empathy, cognitive awareness and convergence between individuals.</p>
    </div>
    
  </div>
</div>
</li></ol>


<h1>International Conference Poster / Demo / Workshop (peer-reviewed)</h1>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">UIST Poster</abbr>
    
  
  </div>

  <div id="10.1145/3332167.3357117" class="col-sm-8">
    
      <div class="title">An Investigation of Electrode Design for Physical Touch Extensions on a Capacitive Touch Surface</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Wang, Xiyue</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ikematsu, Kaori,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fujita, Kazuyuki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Takashima, Kazuki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kitamura, Yoshifumi
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In The Adjunct Publication of the 32nd Annual ACM Symposium on User Interface Software and Technology</em>
      
      
        2019
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://dl.acm.org/doi/10.1145/3332167.3357117" class="btn btn-sm z-depth-0" role="button" target="_blank">DOI</a>
    
    
    
      
      <a href="https://dl.acm.org/doi/pdf/10.1145/3332167.3357117" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>A simple way to prototype touch interaction is to extend electrodes from a capacitive touch screen to off-screen areas. With that we aim to develop a toolkit that transforms a user-designed layout into a layout of screen-extension electrodes that realizes touch for rapid prototyping. Nevertheless, this kind of extension cannot detect touch if the physical properties of the electrodes become large. In this work, we decompose the physical design properties of the extension electrode into two factors, the target area, and line bridge, and investigate the limitation of each separately. While revealing some factors, such as area, is extremely limited in term of designing freely, we look into the causes by measuring the capacitive charge on-screen and on-extensions.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CHI Workshop</abbr>
    
  
  </div>

  <div id="10.1145/3290607.3298996" class="col-sm-8">
    
      <div class="title">Asian CHI Symposium: Emerging HCI Research Collection</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Fujita, Kazuyuki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sari, Eunice,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kim, Juho,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tedjasaputra, Adi,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Do, Ellen Yi-Luen,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Liu, Zhengjie,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lee, Uichin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Monserrat, Toni-Jan Keith Palma,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Matsufuji, Akihiro,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Miyafuji, Shio,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Takada, Ryosuke,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Wacharamanotham, Chat,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ghazali, Masitah,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Wang, Xiyue</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chintakovid, Thippaya,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Seo, Kyoungwon,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kim, Jinwoo,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kitamura, Yoshifumi
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems</em>
      
      
        2019
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://dl.acm.org/doi/10.1145/3290607.3298996" class="btn btn-sm z-depth-0" role="button" target="_blank">DOI</a>
    
    
    
      
      <a href="https://dl.acm.org/doi/pdf/10.1145/3290607.3298996" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This symposium showcases the latest work from Asia on interactive systems and user interfaces that address under-explored problems and demonstrate unique approaches. In addition to circulating ideas and sharing a vision of future research in human-computer interaction, this symposium aims to foster social networks among academics (researchers and students) and practitioners and create a fresh research community from Asian region.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CHI Late-Breaking</abbr>
    
  
  </div>

  <div id="10.1145/3170427.3188451" class="col-sm-8">
    
      <div class="title">Designing Action-Characterizing Toy Blocks for Behavior Assessments</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Wang, Xiyue</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ishikawa, Miteki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Takashima, Kazuki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Adachi, Tomoaki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sharlin, Ehud,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Finn, Patrick,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kitamura, Yoshifumi
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems</em>
      
      
        2018
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://dl.acm.org/doi/10.1145/3170427.3188451" class="btn btn-sm z-depth-0" role="button" target="_blank">DOI</a>
    
    
    
      
      <a href="https://dl.acm.org/doi/pdf/10.1145/3170427.3188451" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="https://youtu.be/2Ys4wNSdT0s" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Playing with toy blocks reveals patterns in children‚Äôs play that are valuable for therapy and assessment. Following the 2011 Tohoku Earthquake and Tsunami in Japan, we witnessed young survivors expressing post-trauma stress in block play. Motivated by the limitations in assessing this behavior using traditional methods, our paper describes the design rationales of AssessBlocks, an action-characterizing system using smartwatch embedded toy blocks. Utilizing a smartwatch‚Äôs Inertial Measurement Unit (IMU) and capacitive screen, a monitor is able to receive, visualize and document sequential and quantitative play actions that were empirically selected from a preliminary block therapy study on children‚Äôs post-disaster stress. We also propose our vision of a multi-dimensional behavioral assessment system using actions obtained by AssessBlocks.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CHI Workshop</abbr>
    
  
  </div>

  <div id="AsianCHI" class="col-sm-8">
    
      <div class="title">Children‚Äôs Blocks: Machine Learning and the Analysis of Motion During Play</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Wang, Xiyue</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ishikawa, Miteki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Takashima, Kazuki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Adachi, Tomoaki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sharlin, Ehud,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Finn, Patrick,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kitamura, Yoshifumi
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In CHI‚Äô18 Asian CHI Symposium</em>
      
      
        2018
      
      
        <b><em>Best Demo/Poster Award</em></b>    
        
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>


</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2025 Xiyue  Wang.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
    Last updated: September 30, 2025.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
